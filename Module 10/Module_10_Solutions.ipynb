{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fgvmlmlhkBg"
      },
      "outputs": [],
      "source": [
        "#Write a program to fetch hyperlinks from any website entered by the user.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        " \n",
        " \n",
        "url = input(\"Write a Properly Formatted HyperLink Please: \")\n",
        "reqs = requests.get(url)\n",
        "soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        " \n",
        "urls = []\n",
        "for link in soup.find_all('a'):\n",
        "    print(link.get('href'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a program to download all the videos from youtube.com for Django from the hyperlink given below.\n",
        "from pytube import YouTube \n",
        "  \n",
        "SAVE_PATH = \"E:/\" \n",
        "\n",
        "link=\"https://www.youtube.com/playlist?list=PLxxA5z-8B2xk4szCgFmgonNcCboyNneMD\"\n",
        "  \n",
        "try: \n",
        "    yt = YouTube(link) \n",
        "except: \n",
        "    print(\"Connection Error\") \n",
        "  \n",
        "mp4files = yt.filter('mp4') \n",
        "\n",
        "yt.set_filename('Django Download')  \n",
        "\n",
        "d_video = yt.get(mp4files[-1].extension,mp4files[-1].resolution) \n",
        "try: \n",
        "    \n",
        "    d_video.download(SAVE_PATH) \n",
        "except: \n",
        "    print(\"Some Error!\") \n",
        "print('Task Completed!') "
      ],
      "metadata": {
        "id": "70kLpD18iiTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform Web Scrapping on the following page \n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "with open(\"C:\\\\Users\\\\Sushil\\\\Edureka Notebooks\\\\Module 10\\\\Module 10 Homework\\\\web.html\") as fp:\n",
        "    soup = BeautifulSoup(fp, \"html.parser\")\n",
        "#Print in a well formatted manner\n",
        "print(soup.prettify())\n",
        "print(\"-----------\")\n",
        "\n",
        "#Print the b tag from the page\n",
        "print(soup.body.p.b)\n",
        "print(\"-----------\")\n",
        "\n",
        "#Print all the tags that start from b\n",
        "print(soup.find_all(\"b\"))\n",
        "\n",
        "#Print text from tags having title and p using lists\n",
        "print(\"-----------\")\n",
        "list_title=[]\n",
        "for i in soup.find_all('title'):\n",
        "    list_title+=i\n",
        "\n",
        "z=0\n",
        "while len(list_title) > z:\n",
        "    print(list_title[z])\n",
        "    z=z+1\n",
        "\n",
        "lists=[]\n",
        "for i in soup.find_all('p'):\n",
        "    lists+=i   \n",
        "z=0\n",
        "while len(lists) > z:\n",
        "    print(lists[z])\n",
        "    z=z+1\n",
        "    \n",
        "#Print text from tags having title and p using dictionaries\n",
        "print(\"-----------\")\n",
        "print(soup.find_all(\"title\"))\n",
        "print(soup.find_all(\"p\"))\n",
        "\n",
        "\n",
        "#Print all the tag names present in the page\n",
        "print(\"-----------\")\n",
        "print(soup.find_all(\"html\"))\n",
        "#Print the tag that has only two attributes\n",
        "attribute = soup.find(align=\"blah\")\n",
        "print(attribute.name)\n",
        "print(\"-----------\")\n",
        "\n",
        "#Print the tags that have one-character names and no attributes\n",
        "no_attributes = soup.find(\"b\")\n",
        "print(no_attributes.name)\n",
        "print(\"-----------\")\n",
        "\n",
        "#Print all the tags which have a value of center for align attribute\n",
        "align = soup.find(align=\"center\")\n",
        "print(align)\n"
      ],
      "metadata": {
        "id": "SbsSheB7kUuF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}